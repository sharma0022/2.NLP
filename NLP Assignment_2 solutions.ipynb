{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3396716",
   "metadata": {},
   "source": [
    "# NLP Assignment_2 solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91893afe",
   "metadata": {},
   "source": [
    "Q.1. What are Corpora?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aec4f83",
   "metadata": {},
   "source": [
    "Ans: Corpora, in the context of linguistics and natural language processing (NLP), refer to large collections of texts or spoken language data that are used for linguistic analysis, language modeling, and various other language-related tasks. A corpus (plural: corpora) is essentially a structured and organized repository of linguistic data, typically gathered from different sources such as books, articles, websites, speeches, conversations, and more.\n",
    "\n",
    "Corpora serve as valuable resources for studying language patterns, understanding linguistic phenomena, and developing computational models and algorithms for NLP tasks. Linguists and researchers analyze corpora to investigate aspects of language like syntax, semantics, pragmatics, discourse, and sociolinguistics. NLP practitioners and developers utilize corpora to train and evaluate machine learning models for tasks like text classification, machine translation, sentiment analysis, and speech recognition.\n",
    "\n",
    "Corpora can be broadly categorized into two types:\n",
    "\n",
    "1. Text Corpora: These corpora consist of written texts, such as books, articles, websites, newspapers, and social media posts. They can cover various domains and genres, allowing researchers to explore different styles and registers of language.\n",
    "\n",
    "2. Spoken Corpora: These corpora contain transcribed or recorded speech data, capturing natural language usage in conversations, interviews, broadcasts, and other spoken contexts. Spoken corpora are valuable for studying phonetics, phonology, prosody, and discourse analysis.\n",
    "\n",
    "Corpora can be manually created by collecting and annotating data specifically for a particular research project or task. Alternatively, they can be compiled from existing sources, such as publicly available texts or speech recordings. Corpora often undergo preprocessing steps, such as cleaning, tokenization, part-of-speech tagging, and syntactic parsing, to make the data suitable for analysis and modeling.\n",
    "\n",
    "Examples of well-known corpora include the Brown Corpus, Penn Treebank, British National Corpus (BNC), Corpus of Contemporary American English (COCA), and many others, each tailored to specific research objectives or applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d0c3e",
   "metadata": {},
   "source": [
    "Q.2. What are Tokens?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984953f5",
   "metadata": {},
   "source": [
    "In the context of natural language processing (NLP) and computational linguistics, tokens refer to the individual units or elements into which a text or speech data is divided. These units can be words, characters, or subword units, depending on the tokenization scheme used.\n",
    "\n",
    "Tokenization is the process of breaking down a continuous stream of text or speech into discrete tokens. It serves as a fundamental step in NLP tasks, as it enables subsequent analysis, modeling, and processing of language data.\n",
    "\n",
    "Here are a few key points about tokens:\n",
    "\n",
    "1. Word Tokens: Word tokenization is the most common form of tokenization, where a text is divided into individual words. For example, the sentence \"I love eating pizza\" would be tokenized into five word tokens: [\"I\", \"love\", \"eating\", \"pizza\"].\n",
    "\n",
    "2. Character Tokens: In some cases, the tokenization process may split the text into individual characters rather than words. This approach can be useful for certain NLP tasks, such as character-level language modeling or sentiment analysis at the character level.\n",
    "\n",
    "3. Subword Tokens: Subword tokenization involves breaking down words into smaller subword units, such as morphemes or syllables. This approach is particularly beneficial for languages with complex morphology or for handling out-of-vocabulary (OOV) words. Popular subword tokenization algorithms include Byte-Pair Encoding (BPE) and SentencePiece.\n",
    "\n",
    "4. Punctuation and Special Characters: Punctuation marks and special characters, like commas, periods, question marks, and hashtags, are typically treated as separate tokens in tokenization. They provide important contextual information for language understanding.\n",
    "\n",
    "Tokenization not only breaks down text into meaningful units but also handles issues like contractions, hyphenated words, and punctuation marks. Tokenized data is often used as input for various NLP tasks, including part-of-speech tagging, named entity recognition, machine translation, sentiment analysis, and more.\n",
    "\n",
    "It's worth noting that the specific tokenization approach chosen can significantly impact downstream NLP tasks and model performance. Therefore, tokenization should be carefully designed and tailored to suit the objectives of the task and the characteristics of the language being processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fbbe18",
   "metadata": {},
   "source": [
    "Q.What are Unigrams, Bigrams, Trigrams?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5be450",
   "metadata": {},
   "source": [
    "Ans: Unigrams, bigrams, and trigrams are terms used to describe different types of n-grams, which are contiguous sequences of n items (usually words) extracted from a text or corpus. N-grams are commonly used in natural language processing (NLP) and computational linguistics for various tasks such as language modeling, information retrieval, and text classification.\n",
    "\n",
    "1. Unigrams: Unigrams are n-grams of size 1, meaning they consist of individual words in a text. Each word in a sentence is treated as a separate unigram. For example, the sentence \"I love eating pizza\" would have the following unigrams: [\"I\", \"love\", \"eating\", \"pizza\"]. Unigrams provide information about the occurrence and frequency of individual words in a text.\n",
    "\n",
    "2. Bigrams: Bigrams are n-grams of size 2, where adjacent pairs of words are considered as a single unit. Each bigram represents a sequence of two consecutive words in the text. For example, using the same sentence as before, the bigrams would be: [\"I love\", \"love eating\", \"eating pizza\"]. Bigrams capture some level of word order information and can be useful for tasks like language modeling, text generation, and collocation analysis.\n",
    "\n",
    "3. Trigrams: Trigrams are n-grams of size 3, meaning they consist of three consecutive words. Trigrams provide even more context and capture dependencies between three adjacent words. Using the same sentence, the trigrams would be: [\"I love eating\", \"love eating pizza\"]. Trigrams can be helpful in tasks like language modeling, machine translation, and text summarization.\n",
    "\n",
    "N-grams of larger sizes (e.g., four-grams, five-grams) can also be used, but their practicality may decrease as the size increases due to the exponential growth in the number of possible combinations.\n",
    "\n",
    "N-grams are often computed from a corpus or a specific text dataset to capture statistical patterns, frequency distributions, and relationships between words. They serve as features for various NLP applications, such as building language models, extracting features for text classification, sentiment analysis, and information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8836d706",
   "metadata": {},
   "source": [
    "Q.4. How to generate n-grams from text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b987571",
   "metadata": {},
   "source": [
    "Ans: Generating n-grams from text involves the process of breaking down the text into contiguous sequences of n items, typically words. Here's a general approach to generate n-grams from a given text:\n",
    "\n",
    "1. Text Preprocessing: Before generating n-grams, it's often helpful to perform some preprocessing steps to clean the text and remove noise. This can involve removing punctuation, converting text to lowercase, handling special characters, and eliminating stopwords (common words like \"the,\" \"and,\" \"is,\" etc.) that do not carry significant meaning.\n",
    "\n",
    "2. Tokenization: The next step is to tokenize the preprocessed text into individual words. You can use a tokenizer library or function in your programming language of choice to split the text into word tokens. The resulting tokens will form the basis for generating n-grams.\n",
    "\n",
    "3. Generating n-grams: Once you have the word tokens, you can generate n-grams by iterating over the tokens and extracting contiguous sequences of n words. This can be done using a sliding window approach. For example, for bigrams (n=2), you would slide a window of size 2 over the tokens, capturing adjacent pairs of words.\n",
    "\n",
    "   Here's an example Python code snippet that demonstrates how to generate bigrams from a given list of tokens:\n",
    "\n",
    "```python\n",
    "tokens = [\"I\", \"love\", \"eating\", \"pizza\"]\n",
    "\n",
    "bigrams = []\n",
    "for i in range(len(tokens) - 1):\n",
    "    bigrams.append((tokens[i], tokens[i+1]))\n",
    "\n",
    "print(bigrams)\n",
    "```\n",
    "\n",
    "This code will output: `[(\"I\", \"love\"), (\"love\", \"eating\"), (\"eating\", \"pizza\")]`.\n",
    "\n",
    "You can extend this approach to generate trigrams or higher-order n-grams by adjusting the window size accordingly.\n",
    "\n",
    "It's worth noting that the choice of tokenization approach and any additional preprocessing steps may vary depending on the specific requirements of your task and the characteristics of the text data. Additionally, libraries or NLP frameworks often provide built-in functions for generating n-grams, making the process more efficient and convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d598d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'love'), ('love', 'eating'), ('eating', 'pizza')]\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"I\", \"love\", \"eating\", \"pizza\"]\n",
    "\n",
    "bigrams = []\n",
    "for i in range(len(tokens) - 1):\n",
    "    bigrams.append((tokens[i], tokens[i+1]))\n",
    "\n",
    "print(bigrams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d13cffd",
   "metadata": {},
   "source": [
    "Q.5. Explain Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b0085",
   "metadata": {},
   "source": [
    "Ans: Lemmatization is a linguistic process used in natural language processing (NLP) to reduce words to their base or canonical form, known as the lemma. The lemma represents the dictionary form or the common root of a word, disregarding its inflections or variations.\n",
    "\n",
    "The purpose of lemmatization is to normalize words, ensuring that different forms of the same word are treated as a single entity. For example, the lemmatization process would convert words like \"walking,\" \"walked,\" and \"walks\" to their lemma \"walk.\"\n",
    "\n",
    "Here are some key points about lemmatization:\n",
    "\n",
    "1. Reducing Word Variations: Lemmatization aims to reduce words to their base forms, taking into account morphological analysis and grammatical context. It involves removing suffixes, prefixes, and other inflections to find the lemma that represents the word's essential meaning.\n",
    "\n",
    "2. Linguistic Considerations: Unlike stemming, which uses heuristics to chop off word endings, lemmatization relies on a deeper understanding of language and relies on dictionaries or morphological rules specific to a language. It considers factors such as part of speech (noun, verb, adjective, etc.) and grammatical features to generate accurate lemmas.\n",
    "\n",
    "3. Improved Coherence: Lemmatization helps in creating more coherent and semantically meaningful representations of text. By reducing words to their base form, it brings together different surface forms of a word, making it easier to identify relationships between words and extract meaningful insights from the text.\n",
    "\n",
    "4. Lemmatization vs. Stemming: Lemmatization is often considered more advanced and accurate than stemming. Stemming typically applies simple rules to remove word endings, resulting in the stem, which may not always be a valid word. In contrast, lemmatization produces lemmas that are actual words and preserve the core meaning of the word.\n",
    "\n",
    "5. Part-of-Speech Tagging: In many lemmatization systems, part-of-speech (POS) tagging is performed alongside the lemmatization process. POS tagging helps disambiguate words with multiple meanings based on their role in the sentence. For instance, \"running\" could be a verb or an adjective, and POS tagging helps determine the correct lemma based on the context.\n",
    "\n",
    "Lemmatization is commonly used in various NLP applications, including information retrieval, question-answering systems, machine translation, text classification, and sentiment analysis. It aids in improving the accuracy of these tasks by reducing word variations and aligning similar word forms under a common lemma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e4da04",
   "metadata": {},
   "source": [
    "Q.6.Explain Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dac5d2",
   "metadata": {},
   "source": [
    "Ans: Stemming is a linguistic process used in natural language processing (NLP) to reduce words to their base or root form, known as the stem. The stem is obtained by removing prefixes, suffixes, and other affixes from a word while attempting to retain its core meaning. The purpose of stemming is to normalize words and reduce them to a common form, treating different variations of a word as the same entity.\n",
    "\n",
    "Here are some key points about stemming:\n",
    "\n",
    "1. Word Stemming: Stemming aims to simplify words by removing derivational and inflectional affixes. Derivational affixes change the word's part of speech or meaning (e.g., \"happy\" to \"happiness\"), while inflectional affixes alter the word's grammatical function or tense (e.g., \"walk\" to \"walked\"). The stemming process applies heuristics or rule-based methods to cut off these affixes and obtain the stem.\n",
    "\n",
    "2. Heuristic Approach: Stemming algorithms follow pattern-based rules and heuristics to identify and remove affixes. They don't rely on linguistic knowledge or contextual analysis but rather use straightforward rules to trim word endings. This may result in stems that are not always actual words but instead represent a generalized form.\n",
    "\n",
    "3. Language Variations: Stemming algorithms vary based on the language being processed since different languages have different morphological rules and affix patterns. There are several popular stemming algorithms available for different languages, such as the Porter stemming algorithm for English and the Snowball stemming algorithm that supports multiple languages.\n",
    "\n",
    "4. Performance and Accuracy: Stemming algorithms are computationally efficient, making them suitable for large-scale text processing. However, stemming is a more aggressive normalization technique compared to lemmatization, as it may produce stems that are not actual words and can potentially introduce ambiguity.\n",
    "\n",
    "5. Example: Consider the word \"running.\" Applying a stemming algorithm to it would likely produce the stem \"run.\" Similarly, words like \"walked,\" \"walks,\" and \"walking\" would all be stemmed to \"walk.\" The goal is to bring together different surface forms of a word to simplify text analysis and improve information retrieval.\n",
    "\n",
    "Stemming is commonly used in various NLP tasks such as information retrieval, search engines, and text mining, where the focus is on word frequency and basic analysis rather than preserving the semantic meaning of the words. However, in cases where the accurate identification of word forms and their semantic relationships is essential, lemmatization is often preferred over stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838758ea",
   "metadata": {},
   "source": [
    "Q.7. Explain Part-of-speech (POS) tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169425c9",
   "metadata": {},
   "source": [
    "Ans:Part-of-speech (POS) tagging, also known as POS labeling or grammatical tagging, is a process in natural language processing (NLP) that assigns grammatical labels or tags to each word in a sentence, indicating its syntactic category and role in the sentence. The assigned POS tags provide information about the word's part of speech, such as noun, verb, adjective, adverb, pronoun, preposition, conjunction, and more.\n",
    "\n",
    "Here are some key points about POS tagging:\n",
    "\n",
    "1. Grammatical Categorization: POS tagging involves classifying each word into specific grammatical categories based on its syntactic function in the sentence. These categories capture the word's role, behavior, and relationships with other words, which is crucial for understanding the structure and meaning of a sentence.\n",
    "\n",
    "2. Disambiguation: POS tagging helps disambiguate words with multiple meanings. Many words in natural language have different grammatical roles depending on the context in which they appear. POS tagging considers the context of the word in the sentence and assigns the appropriate tag to disambiguate its meaning.\n",
    "\n",
    "3. Context Dependency: POS tagging takes into account the surrounding words and the grammatical context to assign the appropriate tag. For instance, the word \"run\" can be a noun or a verb, and POS tagging helps differentiate between \"run\" as a noun (e.g., \"a morning run\") and \"run\" as a verb (e.g., \"to run a marathon\").\n",
    "\n",
    "4. Tag Sets: POS tags are defined according to specific tag sets or taggers, which may vary depending on the linguistic framework or language being analyzed. Popular tag sets include the Penn Treebank tag set for English and the Universal Dependencies tag set that aims for cross-linguistic consistency.\n",
    "\n",
    "5. POS Tagging Techniques: POS tagging can be accomplished using rule-based approaches, statistical methods, or machine learning techniques. Rule-based taggers rely on handcrafted grammatical rules to assign tags, statistical taggers employ probabilistic models trained on annotated corpora, and machine learning taggers utilize supervised or unsupervised learning algorithms to learn patterns and make predictions.\n",
    "\n",
    "6. Applications: POS tagging plays a crucial role in various NLP applications, such as part-of-speech-based parsing, named entity recognition, information retrieval, sentiment analysis, machine translation, text generation, and more. It provides valuable linguistic information that helps improve the accuracy and understanding of these tasks.\n",
    "\n",
    "Overall, POS tagging is a fundamental step in NLP that assigns grammatical labels to words, aiding in syntactic analysis, semantic understanding, and subsequent language processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f0d7f",
   "metadata": {},
   "source": [
    "Q.8. Explain Chunking or shallow parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a5238",
   "metadata": {},
   "source": [
    "Ans: Chunking, also known as shallow parsing or partial parsing, is a natural language processing (NLP) technique that involves grouping words together into meaningful syntactic units called chunks. Chunking aims to identify and extract phrases or noun phrases (NP), verb phrases (VP), prepositional phrases (PP), and other chunk types from a sentence, without providing a complete syntactic parse tree like in full parsing.\n",
    "\n",
    "Here are some key points about chunking:\n",
    "\n",
    "1. Chunk Types: Chunking identifies and groups words based on their syntactic role and relationships within a sentence. Common chunk types include noun phrases (e.g., \"the cat\"), verb phrases (e.g., \"ate the fish\"), prepositional phrases (e.g., \"on the table\"), and others, depending on the specific chunking scheme or linguistic framework used.\n",
    "\n",
    "2. Grammatical Patterns: Chunking relies on grammatical patterns and rules to identify and label chunks. These patterns are often defined using regular expressions or finite-state grammar rules that capture specific sequences of part-of-speech (POS) tags or lexical patterns indicative of particular chunk types.\n",
    "\n",
    "3. Chunking Process: The chunking process typically involves three steps: tokenization, part-of-speech tagging, and chunk identification. First, the sentence is tokenized into words or tokens. Then, each token is assigned a part-of-speech tag, indicating its grammatical category. Finally, the POS-tagged sentence is processed to identify and group words into chunks based on the defined chunking rules.\n",
    "\n",
    "4. Example: Consider the sentence \"The black cat sat on the mat.\" A simple chunking scheme might identify the following chunks: [The black cat] [sat] [on the mat]. Here, the chunks are indicated by square brackets, and each chunk represents a meaningful syntactic unit.\n",
    "\n",
    "5. Applications: Chunking has various applications in NLP. It can be used to extract noun phrases for information extraction tasks, identify verb phrases for semantic analysis, or extract prepositional phrases for understanding relationships between entities. Chunking serves as an intermediate step in more complex parsing tasks and can be useful for tasks like named entity recognition, text summarization, and information retrieval.\n",
    "\n",
    "Chunking differs from full parsing in that it does not produce a complete parse tree or provide a detailed analysis of the grammatical structure. Instead, it focuses on identifying and extracting chunks of words that form meaningful units within a sentence, offering a less complex but still valuable representation of the syntactic information present in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa78ece",
   "metadata": {},
   "source": [
    "Q.9. Explain Noun Phrase (NP) chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42119391",
   "metadata": {},
   "source": [
    "Ans: Noun Phrase (NP) chunking, also known as NP chunking or noun chunking, is a specific type of chunking in natural language processing (NLP) that focuses on identifying and extracting noun phrases from a sentence. Noun phrases are syntactic units that consist of a noun and any modifiers, determiners, or adjectives that accompany it.\n",
    "\n",
    "Here are some key points about noun phrase chunking:\n",
    "\n",
    "1. Definition of Noun Phrase: A noun phrase (NP) is a phrase that includes a noun as its head and may contain other words that modify or describe the noun. It typically consists of determiners (such as articles), adjectives, quantifiers, and other modifiers that provide additional information about the noun. For example, in the sentence \"The big red apple,\" the noun phrase is \"The big red apple,\" where \"apple\" is the head noun, and \"The,\" \"big,\" and \"red\" are modifiers.\n",
    "\n",
    "2. Purpose of NP Chunking: NP chunking aims to identify and extract noun phrases from sentences. It is particularly useful in various NLP tasks, such as information extraction, named entity recognition, text summarization, and relation extraction. By identifying and extracting noun phrases, the structure and key elements of a sentence can be better understood and utilized in downstream applications.\n",
    "\n",
    "3. Chunking Process: NP chunking typically involves a sequence of steps, including tokenization, part-of-speech (POS) tagging, and chunk identification. First, the sentence is tokenized into individual words or tokens. Then, each token is assigned a part-of-speech tag, which indicates its grammatical category. Finally, the POS-tagged sentence is processed to identify and extract noun phrases based on specific grammatical patterns and rules.\n",
    "\n",
    "4. Example: Consider the sentence \"John bought a beautiful house.\" NP chunking would identify the noun phrase \"a beautiful house,\" where \"house\" is the head noun and \"a\" and \"beautiful\" are modifiers. The chunking result would be [John] [bought] [a beautiful house], where the noun phrase is indicated by square brackets.\n",
    "\n",
    "5. Noun Phrase Chunking Techniques: NP chunking can be performed using rule-based approaches or statistical methods. Rule-based techniques often rely on patterns defined using regular expressions or grammatical rules to identify noun phrases based on specific POS tag patterns. Statistical methods utilize machine learning algorithms trained on annotated data to predict noun phrases based on features such as POS tags, word context, and syntactic dependencies.\n",
    "\n",
    "Noun phrase chunking is a valuable technique in NLP for extracting and understanding the key elements and structure of sentences. It helps in capturing important noun phrases that convey significant information and context, enabling more accurate and effective text processing and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a62a8f",
   "metadata": {},
   "source": [
    "Q.10. Explain Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47f71c",
   "metadata": {},
   "source": [
    "Ans: Named Entity Recognition (NER) is a natural language processing (NLP) task that involves identifying and classifying named entities in text into predefined categories such as person names, organizations, locations, dates, numerical quantities, and more. Named entities are specific named entities or proper nouns that refer to unique individuals, places, organizations, and other entities.\n",
    "\n",
    "Here are some key points about Named Entity Recognition:\n",
    "\n",
    "1. Definition of Named Entities: Named entities are specific words or phrases that refer to unique entities in the real world, such as people, places, organizations, dates, products, and more. For example, in the sentence \"Apple Inc. was founded by Steve Jobs in 1976,\" the named entities are \"Apple Inc.,\" \"Steve Jobs,\" and \"1976.\"\n",
    "\n",
    "2. Purpose of NER: The primary goal of NER is to identify and classify named entities in text, enabling the extraction of valuable information and facilitating various downstream NLP tasks. NER is essential in applications such as information extraction, question answering, chatbots, sentiment analysis, and text summarization.\n",
    "\n",
    "3. Approaches to NER: NER can be performed using rule-based approaches, statistical models, or deep learning techniques. Rule-based approaches use handcrafted patterns or regular expressions to match named entities based on specific rules or patterns. Statistical models, such as Conditional Random Fields (CRF) or Hidden Markov Models (HMM), learn patterns from annotated training data to make predictions. Deep learning models, such as recurrent neural networks (RNNs) or transformers, can also be used for NER, leveraging large annotated datasets and powerful contextual representations.\n",
    "\n",
    "4. Training Data and Annotation: NER models require annotated training data, where human annotators label the named entities in a corpus of text. The annotators mark the boundaries of the named entities and assign them to appropriate predefined categories. This annotated data is used to train the NER model, which can then generalize to recognize named entities in unseen text.\n",
    "\n",
    "5. Evaluation: NER systems are evaluated based on metrics such as precision, recall, and F1 score. Precision measures the proportion of correctly identified named entities out of all the identified entities, while recall measures the proportion of correctly identified entities out of all the true entities. The F1 score is the harmonic mean of precision and recall, providing a balanced measure of performance.\n",
    "\n",
    "6. Challenges in NER: NER can be challenging due to the ambiguity and variability of named entities in text. It requires handling entity mentions that can have multiple words, handling unseen entities, dealing with out-of-vocabulary words, and resolving entity boundaries in complex sentences. Additionally, multilingual NER introduces additional challenges, including language-specific characteristics and lack of annotated data.\n",
    "\n",
    "Named Entity Recognition is a crucial NLP task that plays a vital role in information extraction and understanding unstructured text. By identifying and categorizing named entities, NER enables more advanced analysis, retrieval, and interpretation of textual data, contributing to a wide range of applications across industries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845c32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98f2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0196b22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73990d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c9b563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b229c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963107b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa2c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92138b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df3136c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c889d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbba7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76adec32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6157a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4afe78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ada7f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4c3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1f4285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c7e51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b281e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d6418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6930126c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b37541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb207c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815cad75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af194676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd95c87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce561d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdece2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db574d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f5497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92088450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c08f26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcebdd79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274907f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f2e613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba8b780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae1d824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f40e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0b979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27765d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd6c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f0f7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a53a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72669d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ff9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d258af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5dc662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade70e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472137e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f33d37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c39332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d48ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa701771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be05838d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b19eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06404dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbffee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd0ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb741e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0b2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29657f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825790e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eab3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb9066d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ae197d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5871cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f232db1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e133ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb77184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b1da56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c1ce3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c68d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92257af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe98ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff912b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3100e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba15bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c55e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e03c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef1f442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25169a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d82ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743c953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed2a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b159e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e3f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64abec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055617b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd6719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c6348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f3a2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea77bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e05dba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29877bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4309797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4d4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a9f25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba660de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccea7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a8b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133efc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b453adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f9abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a998cb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc8e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e0bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41721f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5419aae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75960fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13db61a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dbc8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731b0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247e71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94baff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5187adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c23d358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68243c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e972ae79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53429c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292808d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e9961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e28b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e6b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39c616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9facfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f195c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e95f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d6141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075bae43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c8d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ecf7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95593b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b9af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f47651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610a1b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48fecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bcfecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ff26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e123e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ba04c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a6244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf41830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eebb035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16922832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ad416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa7a191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e3302e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f527f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcbec0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebefbac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c74d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b984eb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f26006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad3db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2259f0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e2de3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb20e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c2a9db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a90b87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e7d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb19538e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce4f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e559b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84fe38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2debd1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7e7de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb132446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfec64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00864a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef0b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ddfb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968cc7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe23ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0e7551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08514712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
